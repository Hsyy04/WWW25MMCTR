{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fuxictr.preprocess.feature_processor.FeatureProcessor object at 0x7fe8a3eecd90>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/MicroLens_1M_x1/feature_processor.pkl\", \"rb\") as f:\n",
    "    feature_processor = pickle.load(f)\n",
    "print(feature_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_id  likes_level  views_level\n",
      "0        1            7            2\n",
      "1        2            5            9\n",
      "2        3            2            2\n",
      "3        4            2            1\n",
      "4        5            7            5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_name = \"EMB_all_emb_cb07_d\"\n",
    "new_emb = pd.read_parquet(f\"data/MicroLens_1M_x1/{data_name}.parquet\")\n",
    "item_feature = pd.read_parquet(\"dataset/MicroLens_1M_MMCTR/item_feature.parquet\")[[\"item_id\", \"likes_level\",  \"views_level\"]]\n",
    "\n",
    "print(item_feature.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_emb = pd.merge(new_emb, item_feature, on=\"item_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_id        item_tags  \\\n",
      "0        0  [0, 0, 0, 0, 0]   \n",
      "1        1  [0, 0, 0, 0, 1]   \n",
      "2        2  [0, 0, 2, 3, 4]   \n",
      "3        3  [0, 0, 5, 6, 7]   \n",
      "4        4  [0, 0, 0, 8, 9]   \n",
      "\n",
      "                                       item_emb_d128  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [-0.587724506855011, -0.38462838530540466, 0.4...   \n",
      "2  [-2.5054404735565186, 1.5605803728103638, 0.23...   \n",
      "3  [-1.0391175746917725, 1.031670093536377, -0.45...   \n",
      "4  [0.1128326952457428, -0.7956982254981995, 0.70...   \n",
      "\n",
      "                                             dis_emb  likes  views  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    NaN    NaN  \n",
      "1  [153, 30, 550, 205, 493, 592, 899, 175, 229, 4...    7.0    2.0  \n",
      "2  [46, 720, 446, 121, 874, 239, 336, 510, 209, 1...    5.0    9.0  \n",
      "3  [234, 381, 730, 200, 6, 852, 71, 1012, 981, 57...    2.0    2.0  \n",
      "4  [726, 85, 145, 206, 258, 285, 472, 777, 660, 5...    2.0    1.0  \n"
     ]
    }
   ],
   "source": [
    "all_emb = all_emb.rename(columns={\"likes_level\": \"likes\", \"views_level\": \"views\"})\n",
    "# all_emb.fillna(0, inplace=True)\n",
    "print(all_emb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_emb.to_parquet(f\"data/MicroLens_1M_x1/{data_name}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_parquet(\"dataset/MicroLens_1M_MMCTR/item_seq.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                           item_seq\n",
       "0        1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1        1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2        1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3        1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4        1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000000/6000000 [07:50<00:00, 12746.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    6.000000e+06\n",
       "mean     7.973784e+00\n",
       "std      7.234855e+00\n",
       "min      3.000000e+00\n",
       "25%      4.000000e+00\n",
       "50%      6.000000e+00\n",
       "75%      9.000000e+00\n",
       "max      1.000000e+02\n",
       "Name: len, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "lens = []\n",
    "for i, item in tqdm(data.iterrows(), total=len(data)):\n",
    "    one_item = item[\"item_seq\"]\n",
    "    while(one_item[0] == 0):\n",
    "        one_item = one_item[1:]\n",
    "    lens.append(len(one_item))\n",
    "\n",
    "data[\"len\"] = lens\n",
    "data[\"len\"].describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gpt/qwen embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "raw_data = pd.read_parquet(\"dataset/MicroLens_1M_MMCTR/item_feature_gpt.parquet\")\n",
    "qwen_data = np.load(\"dataset/qw_data_all.npy\").tolist()\n",
    "raw_data[\"img_emb_QWEN\"] = qwen_data\n",
    "raw_data.to_parquet(\"dataset/MicroLens_1M_MMCTR/item_feature_gpt_qwen.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyshao/anaconda3/envs/fuxictr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_id        item_tags  \\\n",
      "0        0  [0, 0, 0, 0, 0]   \n",
      "1        1  [0, 0, 0, 0, 1]   \n",
      "2        2  [0, 0, 2, 3, 4]   \n",
      "3        3  [0, 0, 5, 6, 7]   \n",
      "4        4  [0, 0, 0, 8, 9]   \n",
      "\n",
      "                                       item_emb_d128  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [-0.587724506855011, -0.38462838530540466, 0.4...   \n",
      "2  [-2.5054404735565186, 1.5605803728103638, 0.23...   \n",
      "3  [-1.0391175746917725, 1.031670093536377, -0.45...   \n",
      "4  [0.1128326952457428, -0.7956982254981995, 0.70...   \n",
      "\n",
      "                                        dis_emb_clip  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [35, 9, 41, 18, 34, 1, 58, 8, 53, 8, 50, 49, 9...   \n",
      "2  [35, 23, 6, 5, 27, 5, 32, 19, 23, 4, 16, 42, 2...   \n",
      "3  [21, 9, 41, 18, 34, 55, 6, 37, 43, 4, 10, 4, 4...   \n",
      "4  [46, 9, 6, 11, 22, 48, 6, 15, 24, 20, 22, 33, ...   \n",
      "\n",
      "                                         dis_emb_gpt  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [35, 9, 41, 18, 34, 1, 58, 8, 53, 8, 50, 49, 9...  \n",
      "2  [35, 23, 6, 5, 27, 5, 32, 19, 23, 4, 16, 42, 2...  \n",
      "3  [21, 9, 41, 18, 34, 55, 6, 37, 43, 4, 10, 4, 4...  \n",
      "4  [46, 9, 6, 11, 22, 48, 6, 15, 24, 20, 22, 33, ...  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "raw_data = pd.read_parquet(\"dataset/MicroLens_1M_MMCTR/item_feature.parquet\")\n",
    "item_info = pd.read_parquet(\"data/MicroLens_1M_x1/item_info.parquet\")\n",
    "clip_disc_data = torch.load(\"data/indices_clip.pt\")\n",
    "gpt_disc_data = torch.load(\"data/indices_gpt.pt\")\n",
    "# dis_emb = torch.cat([clip_disc_data, gpt_disc_data], dim=1)\n",
    "# print(dis_emb.shape)\n",
    "new_data = pd.DataFrame()\n",
    "new_data[\"item_id\"] = raw_data[\"item_id\"]\n",
    "new_data[\"dis_emb_clip\"] = clip_disc_data.tolist()\n",
    "new_data[\"dis_emb_gpt\"] = clip_disc_data.tolist()\n",
    "new_data = pd.merge(item_info, new_data, on=\"item_id\", how=\"left\")\n",
    "new_data.at[0, \"dis_emb_clip\"]=[0 for i in range(len(clip_disc_data[0]))]\n",
    "new_data.at[0, \"dis_emb_gpt\"]=[0 for i in range(len(gpt_disc_data[0]))]\n",
    "print(new_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_parquet(\"data/MicroLens_1M_x1/item_info_ljh2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_id        item_tags  \\\n",
      "0        0  [0, 0, 0, 0, 0]   \n",
      "1        1  [0, 0, 0, 0, 1]   \n",
      "2        2  [0, 0, 2, 3, 4]   \n",
      "3        3  [0, 0, 5, 6, 7]   \n",
      "4        4  [0, 0, 0, 8, 9]   \n",
      "\n",
      "                                       item_emb_d128  likes  views  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    NaN    NaN   \n",
      "1  [-0.587724506855011, -0.38462838530540466, 0.4...    7.0    2.0   \n",
      "2  [-2.5054404735565186, 1.5605803728103638, 0.23...    5.0    9.0   \n",
      "3  [-1.0391175746917725, 1.031670093536377, -0.45...    2.0    2.0   \n",
      "4  [0.1128326952457428, -0.7956982254981995, 0.70...    2.0    1.0   \n",
      "\n",
      "                                           feature_0  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [153, 30, 550, 205, 493, 592, 899, 175, 229, 4...   \n",
      "2  [46, 720, 446, 121, 874, 239, 336, 510, 209, 1...   \n",
      "3  [234, 381, 730, 200, 6, 852, 71, 1012, 981, 57...   \n",
      "4  [726, 85, 145, 206, 258, 285, 472, 777, 660, 5...   \n",
      "\n",
      "                                           feature_1  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [356, 470, 833, 211, 383, 688, 428, 763, 479, ...   \n",
      "2  [85, 253, 619, 894, 918, 997, 221, 103, 711, 1...   \n",
      "3  [578, 747, 205, 999, 376, 17, 738, 232, 972, 7...   \n",
      "4  [881, 222, 629, 143, 403, 184, 988, 434, 209, ...   \n",
      "\n",
      "                                           feature_2  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [286, 28, 976, 122, 156, 107, 703, 483, 448, 5...   \n",
      "2  [803, 469, 775, 864, 286, 130, 702, 376, 403, ...   \n",
      "3  [458, 63, 832, 960, 836, 959, 702, 561, 448, 1...   \n",
      "4  [202, 476, 832, 303, 708, 387, 186, 120, 448, ...   \n",
      "\n",
      "                                           feature_3  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [106, 253, 502, 90, 943, 636, 91, 793, 548, 45...  \n",
      "2  [907, 810, 671, 776, 735, 876, 298, 510, 26, 2...  \n",
      "3  [221, 804, 114, 919, 943, 768, 14, 77, 537, 58...  \n",
      "4  [987, 633, 754, 346, 669, 452, 1012, 248, 122,...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml \n",
    "import os\n",
    "info_data = pd.read_parquet(\"../data/MicroLens_1M_x1/EMB_all_emb_cb05_data_4.parquet\")\n",
    "print(info_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuxictr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
